import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.utilities import GoogleSearchAPIWrapper
from langchain_core.messages import HumanMessage

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì§„ë¡œ & ë„ì„œ ì¶”ì²œ ì±—ë´‡", layout="centered")
st.title("ğŸ“ ë¯¸ë˜ì„¤ê³„ ì§„ë¡œ ì±—ë´‡")
st.caption("Gemini 2.5 Flash ê¸°ë°˜ì˜ ì‹¤ì‹œê°„ ìƒë‹´ì†Œ")

# API í‚¤ ë³´ì•ˆ í˜¸ì¶œ
try:
    gemini_api_key = st.secrets["GEMINI_API_KEY"]
    google_cse_id = st.secrets["GOOGLE_CSE_ID"]
    google_api_key = st.secrets["GOOGLE_API_KEY"]
except KeyError as e:
    st.error(f"Secrets ì„¤ì • í™•ì¸ í•„ìš”: {e} í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.stop()

# 2. ëª¨ë¸ ë° ê²€ìƒ‰ ë„êµ¬ ì„¤ì •
# ìºì‹±ì„ ì´ìš©í•´ ì•± ì†ë„ í–¥ìƒ ë° ì¬ì´ˆê¸°í™” ë°©ì§€
@st.cache_resource
def load_tools():
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", 
        google_api_key=gemini_api_key,
        temperature=0.7
    )
    search = GoogleSearchAPIWrapper(
        google_api_key=google_api_key, 
        google_cse_id=google_cse_id
    )
    return llm, search

llm, search = load_tools()

# 3. ì±„íŒ… ì„¸ì…˜ ê´€ë¦¬
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 4. ì±—ë´‡ ì‹¤í–‰ ë¡œì§
if user_input := st.chat_input("ì–´ë–¤ ì§„ë¡œê°€ ê³ ë¯¼ì¸ê°€ìš”?"):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ì¡°ì–¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # 1ë‹¨ê³„: ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
                search_results = search.run(f"{user_input} ê´€ë ¨ í•™ê³¼ ì§„ë¡œ ì¶”ì²œ ë„ì„œ")
                
                # 2ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ìƒì„±
                prompt = f"""
                ë‹¹ì‹ ì€ ì§„ë¡œ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                ì‚¬ìš©ìì˜ ê³ ë¯¼: {user_input}
                
                ì•„ë˜ì˜ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì¹œì ˆí•˜ê²Œ ìƒë‹´í•´ì£¼ê³ , ë°˜ë“œì‹œ ê´€ë ¨ ì¶”ì²œ ë„ì„œ 2ê¶Œì„ ì œëª©ê³¼ í•¨ê»˜ ì†Œê°œí•´ ì£¼ì„¸ìš”.
                ê²€ìƒ‰ ë°ì´í„°: {search_results}
                """
                
                # 3ë‹¨ê³„: Gemini 2.5 Flash í˜¸ì¶œ
                response = llm.invoke([HumanMessage(content=prompt)])
                answer = response.content
                
                st.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})
                
            except Exception as e:
                st.error("ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                st.info("API í‚¤ ìœ íš¨ì„±ì´ë‚˜ Secrets ì„¤ì •ì„ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.")
