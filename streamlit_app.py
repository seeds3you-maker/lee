import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType
from langchain.tools import GoogleSearchRun
from langchain_community.utilities import GoogleSearchAPIWrapper
from langchain.memory import ConversationBufferMemory

# í˜ì´ì§€ ì„¤ì • ë° UI
st.set_page_config(page_title="ë¯¸ë˜ì„¤ê³„ ì§„ë¡œ ì±—ë´‡", layout="centered")
st.title("ğŸ“ ë¯¸ë˜ì„¤ê³„ ì§„ë¡œ & ë„ì„œ ì¶”ì²œ ì±—ë´‡")
st.caption("ì—¬ëŸ¬ë¶„ì˜ ê¿ˆì„ ìœ„í•´ gemini-2.5-flashê°€ ìµœì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¡°ì–¸í•´ ë“œë¦½ë‹ˆë‹¤.")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# API í‚¤ ì„¤ì • (Streamlit Secrets)
try:
    gemini_api_key = st.secrets["GEMINI_API_KEY"]
    google_cse_id = st.secrets["GOOGLE_CSE_ID"]
    google_api_key = st.secrets["GOOGLE_API_KEY"]
except KeyError as e:
    st.error(f"Secrets ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

# 1. ëª¨ë¸ ì„¤ì • (ìµœì‹  gemini-2.5-flash ì‚¬ìš©)
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    google_api_key=gemini_api_key,
    temperature=0.7
)

# 2. ë„êµ¬ ì„¤ì • (ì‹¤ì‹œê°„ ë„ì„œ ë° ì§„ë¡œ ì •ë³´ ê²€ìƒ‰ì„ ìœ„í•œ Google Search)
search = GoogleSearchAPIWrapper(
    google_api_key=google_api_key,
    google_cse_id=google_cse_id
)

tools = [
    Tool(
        name="CareerBookSearch",
        func=search.run,
        description="íŠ¹ì • ì§„ë¡œ ë¶„ì•¼ì˜ ìµœì‹  ë„ì„œ, ë² ìŠ¤íŠ¸ì…€ëŸ¬, ì¶”ì²œ ë„ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
    )
]

# 3. ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
agent_chain = initialize_agent(
    tools,
    llm,
    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
    verbose=True,
    memory=st.session_state.memory,
    handle_parsing_errors=True
)

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
SYSTEM_PROMPT = """ë„ˆëŠ” í•™ìƒë“¤ì˜ ì§„ë¡œë¥¼ ìƒë‹´í•´ì£¼ëŠ” ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì•¼.
ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬ë‚˜ ì „ê³µì— ë§ì¶° êµ¬ì²´ì ì¸ ë¡œë“œë§µì„ ì œì‹œí•´ì£¼ê³ , 
ë°˜ë“œì‹œ 'CareerBookSearch' ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ ë¶„ì•¼ì˜ ìµœì‹  ë² ìŠ¤íŠ¸ì…€ëŸ¬ë‚˜ í‰ì ì´ ì¢‹ì€ ë„ì„œë¥¼ ì°¾ì•„ ì¶”ì²œí•´ì¤˜.
ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ê²©ë ¤í•˜ëŠ” ë§íˆ¬ë¡œ ì‘ì„±í•´ì¤˜."""

# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ì§„ë¡œì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ë‚˜ ê´€ì‹¬ ë¶„ì•¼ë¥¼ ë§ì”€í•´ ì£¼ì„¸ìš”!"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ë©° ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            full_prompt = f"{SYSTEM_PROMPT}\n\nì‚¬ìš©ì ì§ˆë¬¸: {prompt}"
            response = agent_chain.run(input=full_prompt)
            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})