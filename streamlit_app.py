import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain import hub  # ì´ ë°©ì‹ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì—ëŸ¬ ë°©ì§€
from langchain.agents import AgentExecutor, create_react_agent
from langchain_community.utilities import GoogleSearchAPIWrapper
from langchain.tools import Tool

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì§„ë¡œ & ë„ì„œ ì¶”ì²œ ì±—ë´‡", layout="centered")
st.title("ğŸ“ ë¯¸ë˜ì„¤ê³„ ì§„ë¡œ ì±—ë´‡")
st.caption("Gemini 2.5 Flash ê¸°ë°˜ì˜ ì‹¤ì‹œê°„ ìƒë‹´ì†Œ")

# API í‚¤ ë³´ì•ˆ í˜¸ì¶œ
try:
    gemini_api_key = st.secrets["GEMINI_API_KEY"]
    google_cse_id = st.secrets["GOOGLE_CSE_ID"]
    google_api_key = st.secrets["GOOGLE_API_KEY"]
except KeyError as e:
    st.error(f"Secrets ì„¤ì • í™•ì¸ í•„ìš”: {e} í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.stop()

# 2. ëª¨ë¸ ë° ë„êµ¬ ì„¤ì •
@st.cache_resource
def init_agent():
    # ìµœì‹  ì•ˆì •í™” ëª¨ë¸ Gemini 2.5 Flash
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", 
        google_api_key=gemini_api_key,
        temperature=0.7
    )
    
    # êµ¬ê¸€ ê²€ìƒ‰ ì—”ì§„ ì„¤ì •
    search = GoogleSearchAPIWrapper(
        google_api_key=google_api_key, 
        google_cse_id=google_cse_id
    )
    
    tools = [
        Tool(
            name="Search",
            func=search.run,
            description="ì§„ë¡œ ì •ë³´, ë² ìŠ¤íŠ¸ì…€ëŸ¬ ë„ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
        )
    ]
    
    # ReAct í”„ë¡¬í”„íŠ¸ ë¡œë“œ (ê³µì‹ ê°€ì´ë“œë¼ì¸ ë°©ì‹)
    # ì—¬ê¸°ì„œ ì—ëŸ¬ê°€ ë‚œë‹¤ë©´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ê°€ ëœ ëœ ê²ƒì´ë¯€ë¡œ Rebootì´ í•„ìš”í•©ë‹ˆë‹¤.
    try:
        prompt = hub.pull("hwchase17/react")
    except Exception:
        # hub.pullì´ ì‹¤íŒ¨í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë°±ì—…
        from langchain_core.prompts import PromptTemplate
        template = "Answer the following questions as best you can. You have access to the following tools: {tools}\n\nUse the following format:\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\n\nQuestion: {input}\nThought: {agent_scratchpad}"
        prompt = PromptTemplate.from_template(template)
    
    # ì—ì´ì „íŠ¸ ìƒì„±
    agent = create_react_agent(llm, tools, prompt)
    return AgentExecutor(
        agent=agent, 
        tools=tools, 
        verbose=True, 
        handle_parsing_errors=True
    )

try:
    agent_executor = init_agent()
except Exception as e:
    st.error(f"ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()

# 3. ì±„íŒ… UI êµ¬ì„±
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if user_input := st.chat_input("ì–´ë–¤ ì§„ë¡œê°€ ê³ ë¯¼ì¸ê°€ìš”?"):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ë©° ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            prompt_query = f"ì‚¬ìš©ìì˜ ì§ˆë¬¸: {user_input}. ê´€ë ¨ ì§„ë¡œ ë„ì„œë¥¼ ê²€ìƒ‰í•˜ì—¬ ì¶”ì²œí•˜ê³  ìƒë‹´í•´ì¤˜."
            try:
                response = agent_executor.invoke({"input": prompt_query})
                answer = response["output"]
                st.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})
            except Exception as e:
                st.error("ë‹µë³€ ìƒì„± ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                st.info("API í‚¤ ê¶Œí•œì´ë‚˜ í• ë‹¹ëŸ‰ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
