import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
import langchainhub as hub
# ì„í¬íŠ¸ ê²½ë¡œë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•˜ì—¬ ì—ëŸ¬ ë°©ì§€
from langchain.agents.agent import AgentExecutor
from langchain.agents.react.agent import create_react_agent
from langchain_community.utilities import GoogleSearchAPIWrapper
from langchain.tools import Tool

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì§„ë¡œ & ë„ì„œ ì¶”ì²œ ì±—ë´‡", layout="centered")
st.title("ğŸ“ ë¯¸ë˜ì„¤ê³„ ì§„ë¡œ ì±—ë´‡")
st.caption("Gemini 2.5 Flash ê¸°ë°˜ì˜ ì‹¤ì‹œê°„ ìƒë‹´ì†Œ")

# API í‚¤ ë³´ì•ˆ í˜¸ì¶œ
try:
    gemini_api_key = st.secrets["GEMINI_API_KEY"]
    google_cse_id = st.secrets["GOOGLE_CSE_ID"]
    google_api_key = st.secrets["GOOGLE_API_KEY"]
except KeyError as e:
    st.error(f"Secrets ì„¤ì • í™•ì¸ í•„ìš”: {e} í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.stop()

# 2. ëª¨ë¸ ë° ë„êµ¬ ì„¤ì •
@st.cache_resource
def init_agent():
    # ìµœì‹  ì•ˆì •í™” ëª¨ë¸ Gemini 2.5 Flash
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", 
        google_api_key=gemini_api_key,
        temperature=0.7
    )
    
    # êµ¬ê¸€ ê²€ìƒ‰ ì—”ì§„ ì„¤ì •
    search = GoogleSearchAPIWrapper(
        google_api_key=google_api_key, 
        google_cse_id=google_cse_id
    )
    
    tools = [
        Tool(
            name="Search",
            func=search.run,
            description="ì§„ë¡œ ì •ë³´, ë² ìŠ¤íŠ¸ì…€ëŸ¬ ë„ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
        )
    ]
    
    # ReAct í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt = hub.pull("hwchase17/react")
    
    # ì—ì´ì „íŠ¸ ìƒì„± (ìµœì‹  ë°©ì‹)
    agent = create_react_agent(llm, tools, prompt)
    return AgentExecutor(
        agent=agent, 
        tools=tools, 
        verbose=True, 
        handle_parsing_errors=True
    )

try:
    agent_executor = init_agent()
except Exception as e:
    st.error(f"ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()

# 3. ì±„íŒ… UI êµ¬ì„±
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if user_input := st.chat_input("ì–´ë–¤ ì§„ë¡œê°€ ê³ ë¯¼ì¸ê°€ìš”?"):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("ìµœì‹  ë„ì„œì™€ ì •ë³´ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
            prompt_query = f"ì‚¬ìš©ì ì§ˆë¬¸: {user_input}. ê´€ë ¨ ì§„ë¡œ ë„ì„œë¥¼ ê²€ìƒ‰í•˜ì—¬ ì¶”ì²œí•˜ê³  ìƒë‹´í•´ì¤˜."
            try:
                # ìµœì‹  invoke ë°©ì‹ ì‚¬ìš©
                response = agent_executor.invoke({"input": prompt_query})
                answer = response["output"]
                st.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})
            except Exception as e:
                st.error("ë‹µë³€ ìƒì„± ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                st.info("ê²€ìƒ‰ API í• ë‹¹ëŸ‰ì´ë‚˜ í‚¤ ì„¤ì •ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
